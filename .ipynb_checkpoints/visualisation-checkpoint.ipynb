{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044dd571",
   "metadata": {},
   "source": [
    "## AI lab project: Traffic sign detection\n",
    "\n",
    "### Packages used:\n",
    "\n",
    "- The ElementTree XML API - https://docs.python.org/3/library/xml.etree.elementtree.html\n",
    "- OpenCV - https://opencv.org/\n",
    "- glob - https://docs.python.org/3/library/glob.html\n",
    "- numpy - https://numpy.org/doc/\n",
    "- random - https://docs.python.org/3/library/random.html\n",
    "- sklearn.ensemble - https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f1058",
   "metadata": {},
   "source": [
    "### In order to edit the file, run imports and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72231c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e657f",
   "metadata": {},
   "source": [
    "Change this cell type to code and paste all functions in main.py except main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19fec9",
   "metadata": {},
   "source": [
    "### Algorithms used:\n",
    "\n",
    "parse_data(path) - `main.py, lines 9-79`: Parsing .xml files and putting data in a custom structure.\n",
    "\n",
    "Structure below contains list of samples, where values of first sample, first object are printed. All samples are arranged in a dictionary structure. Dictionary keys are: **{** name, image, size: { width, height }, object: \\[ { type, bounds: { xmin, ymin, xmax, ymax }, obj_image } \\] **}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd7d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road0.png\n",
      "267\n",
      "400\n",
      "2\n",
      "98\n",
      "62\n",
      "208\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "train_data = parse_data('train\\\\annotations\\\\')\n",
    "print(train_data[0]['name'])\n",
    "# print(train_data[0]['image']) # large matrix, feel free to uncomment\n",
    "print(train_data[0]['size']['width'])\n",
    "print(train_data[0]['size']['height'])\n",
    "print(train_data[0]['object'][0]['type'])\n",
    "print(train_data[0]['object'][0]['bounds']['xmin'])\n",
    "print(train_data[0]['object'][0]['bounds']['ymin'])\n",
    "print(train_data[0]['object'][0]['bounds']['xmax'])\n",
    "print(train_data[0]['object'][0]['bounds']['ymax'])\n",
    "# print(train_data[0]['object'][0]['obj_image']) # large matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631034b",
   "metadata": {},
   "source": [
    "*balance_dataset(data, ratio)* - `main.py, lines 81-87`: Reduce elements of dataset, randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a338140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of elements: 877\n",
      "Balancing with low ratio:\n",
      "road299.png\n",
      "road770.png\n",
      "road739.png\n",
      "road514.png\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for sample in train_data:\n",
    "    i += 1\n",
    "print('Num of elements:', i)\n",
    "\n",
    "print('Balancing with low ratio:')\n",
    "balanced = balance_dataset(train_data, 0.005)\n",
    "for sample in balanced:\n",
    "    print(sample['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9b6b7",
   "metadata": {},
   "source": [
    "*learn_bovw(data)* - `main.py, lines 89-108`: Creates a dictionary of visual words from cropped traffic light images. Creates a voc.npy file. Remember to comment out after creating a dictionary file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b324826",
   "metadata": {},
   "source": [
    "*extract_features(data)* - `main.py, lines 111-126`: Creates key points in cropped images and determines if they match the vocabulary in the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f8492",
   "metadata": {},
   "source": [
    "*train(data)* - `main.py, lines 130-144`: Trains random forest model and returns it from function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8915d",
   "metadata": {},
   "source": [
    "*predict(rf, data)* - `main.py, lines 146-156`: Performs prediction using trained model and adds results as \"type_pred\" (int) entry in object_data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c6bb3",
   "metadata": {},
   "source": [
    "*check_size(sample, objects)* - `main.py, lines 159-170`: Returns True if size of object is greater or equal to 10% of the image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9d526c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_size(train_data[0], train_data[0]['object'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f17fb",
   "metadata": {},
   "source": [
    "*print_predicted(data)* - `main.py, lines 173-193`: Prints detected crosswalks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c1154",
   "metadata": {},
   "source": [
    "*test_print(data)* - `main.py, lines 196-207`: Function used for debugging."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
